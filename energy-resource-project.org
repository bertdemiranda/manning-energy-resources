* Links 
** DropWizard
   [[https://www.dropwizard.io/en/latest/manual/core.html][Dropwizard Core]]
   [[https://www.dropwizard.io/en/latest/manual/core.html#managed-objects][DropWizard Managed Objects]]
   [[https://howtodoinjava.com/dropwizard/tutorial-and-hello-world-example/][Dropwizard Tutorial – Hello World Example]]
** Avro, Schema
   [[http://avro.apache.org/docs/current/gettingstartedjava.html][Apache Avro™ 1.10.0 Getting Started (Java)]]
   Docs Build Applications for Kafka -> [[https://docs.confluent.io/current/schema-registry/index.html][Schema Management]] (Confluent)
   [[https://docs.confluent.io/current/schema-registry/schema_registry_tutorial.html#schema-registry-tutorial][Schema Registry Tutorials]] / [[https://docs.confluent.io/current/schema-registry/schema_registry_onprem_tutorial.html#schema-registry-onprem-tutorial][On-Premises Schema Registry Tutorial]] (Confluent)
** Kafka
** [[https://liveproject.manning.com/project/153/52/managing-a-distributed-electrical-grid-in-real-time-with-kafka?][Live Project]]
* Project phase 1 - Ingesting Streaming Events and Realtime Access to Battery State
** The Data

   The following table specifies the fields in the data that are sent by the IoT device 
   to our server. 
   |------------------+-----------+-----------|
   | field name       | Avro type | Java type |
   |------------------+-----------+-----------|
   | device_id        | string    | String    |
   | charging         | int       | int       |
   | charging_source  | string    | String    |
   | current_capacity | int       | int       |
   |------------------+-----------+-----------|

   In addition the webserver adds the following metadata to Kafka:
   |------------+-----------+-----------|
   | field name | Avro type | Java type |
   |------------+-----------+-----------|
   | when       | datetime  | DateTime  |
   |------------+-----------+-----------|

** The Device Event generator
*** Source File [[event-generators/src/main/java/com/jesseyates/manning/EventGenerator.java][EventGenerator.java]] contains a hashmap with possible event fields:
   #+begin_src java
   (...)
   // setup event field values
   {
     events.put("charging", new ImmutablePair<>(-1000, 1000));
     events.put("charging_source", new ImmutablePair<>("solar", "utility"));
     events.put("current_capacity", new ImmutablePair<>(0, 13_000));
     // other fields like a real device would send
     // events.put("moduleL_temp", new ImmutablePair<>(-5, 225));
     // events.put("moduleR_temp", new ImmutablePair<>(-5, 225));
     // events.put("processor1_temp", new ImmutablePair<>(-5, 225));
     // events.put("processor2_temp", new ImmutablePair<>(-5, 225));
     // events.put("processor3_temp", new ImmutablePair<>(-5, 225));
     // events.put("processor4_temp", new ImmutablePair<>(-5, 225));
     // events.put("inverter_state", new ImmutablePair<>(0, 15));
     // events.put("SoC_regulator", new ImmutablePair<>(26.0f, 29.6f));
   }
   (...)
   #+end_src
   The generator generates a random number of events with random field values. 
   The event data is then formatted as a JSON array and POST-ed to the web-server.
*** Compiling/running
    $ cd (...)/event-generators
    $ mvn clean/compile/package
    $ java -jar target/event-generators-1.2-SNAPSHOT-jar-with-dependencies.jar events -e 1 --debug -t http://localhost:8080/device-events
** Dropwizard Webserver
*** Receiving POST-ed Device events
    File [[scaffold/src/main/java/DeviceEventResource.java][DeviceEventResource.java]] sets up the URL /device-events/{devid} for receiving 
    device events with charging data for device with id devid. This handler expects 
    an JSON array of device event records that are decoded into an ArrayList<[[/home/bert/DistributedGridProject/manning-energy-resources/scaffold/src/main/java/DeviceEvent.java][DeviceEvent]]>.
*** GET-ting Device Loading information
*** Compiling/running
    $ cd (...)/scaffold
    $ mvn clean/compile/package
    $ java -jar target/energy-kafka-1.0-SNAPSHOT.jar server ingestbattevents.yml
** Avro Schema
   File [[scaffold/src/main/resources/avro/devicebattevent.avsc][devicebattevent.avsc]] defines the schema to use when sending/receiving device events to/from Kafka.
   It defines a simple record consisting of a list of fields enumerated in the tables above.
   This results in generated Java code in file [[scaffold/src/main/generated/com/example/ingestbattevents/avro/DeviceEventAvro.java][DeviceEventAvro.java]] that can be used for this purpose.
*** Java Producer Code to send incoming device event data through to Kafka
**** DONE Use the Builder to create DeviceEventAvro objects.
    This is a [[https://github.com/confluentinc/examples/blob/6.0.0-post/clients/avro/src/main/java/io/confluent/examples/clients/basicavro/ProducerExample.java][full producer example]].
    The following code was added as a function sendDeviceEventToKafka
    in file [[scaffold/src/main/java/DeviceEventResource.java][DeviceEventResource.java]]:
    #+begin_src java
import io.confluent.kafka.serializers.KafkaAvroSerializer;
(...)
// Added to the DeviceEventResource constructor
props = ....
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class);
(...)
// Added function
    private void sendDeviceEventToKafka(DeviceEvent deviceevent) {
        KafkaProducer<String, DeviceEventAvro> producer = new KafkaProducer<String, DeviceEventAvro>(props);

        DeviceEventAvro.Builder avrobuilder = DeviceEventAvro.newBuilder();
        DeviceEventAvro eventavro = 
            avrobuilder.setDeviceId       (deviceevent.getDevice_id())
                       .setCharging       (deviceevent.getCharging())
                       .setChargingSource (deviceevent.getCharging_source())
                       .setCurrentCapacity(deviceevent.getCurrent_capacity())
                       .build();

        final ProducerRecord<String, DeviceEventAvro> record = new ProducerRecord<String, DeviceEventAvro>(TOPIC, deviceevent.getDevice_id(), eventavro);
        producer.send(record);
    }
    #+end_src
** Running Kafka in container
*** Install Docker c.s.
    [[https://docs.docker.com/engine/install/ubuntu/][install Docker]]
    [[https://docs.docker.com/engine/install/linux-postinstall/][Post-installation steps for Linux]]
    bert@bert-K18Base:~$ sudo groupadd docker
    groupadd: group 'docker' already exists
    bert@bert-K18Base:~$ sudo usermod -aG docker $USER)
    ($ sudo apt install docker-compose)
    $ docker run hello-world
*** Running
    $ cd (...)/scaffold
    $ docker-compose -f docker-compose-kafka.yml up
    $# runs at localhost:29092, schema registry at localhost:8090
**** Log
bert@bert-K18Base:~/DistributedGridProject/manning-energy-resources/scaffold$ curl --silent -X GET http://localhost:8090/subjects/ | jq .
[
  "device-events-value"
]
bert@bert-K18Base:~/DistributedGridProject/manning-energy-resources/scaffold$ curl --silent -X GET http://localhost:8090/subjects/device-events-value/versions/latest | jq .
{
  "subject": "device-events-value",
  "version": 1,
  "id": 41,
  "schema": "{\"type\":\"record\",\"name\":\"DeviceEventAvro\",\"namespace\":\"com.example.ingestbattevents.avro\",\"fields\":[{\"name\":\"device_id\",\"type\":[\"string\",\"null\"],\"default\":\"\"},{\"name\":\"charging\",\"type\":[\"int\",\"null\"],\"default\":0},{\"name\":\"charging_source\",\"type\":[\"string\",\"null\"],\"default\":\"\"},{\"name\":\"current_capacity\",\"type\":[\"int\",\"null\"],\"default\":0}]}"
}
** Kafka Streams
*** Streams configuration
**** streams.StreamsConfiguration.java#streamsConfiguration sets up a configuration for the streams,
**** streams.StreamsConfiguration.java#schemaRegistry returns a map containing the URL of the schema resistry.
*** Device Event Stream topology
    Look at this example how they use Avro Schema's and serialisation/deserialisation.
    folder: file:///media/bert/Data/Areas/Training/KafkaStreamsTutorials/kafka-streams-examples
    file -> file:///media/bert/Data/Areas/Training/KafkaStreamsTutorials/kafka-streams-examples/src/main/java/io/confluent/examples/streams/interactivequeries/kafkamusic/KafkaMusicExample.java

    [[file:///home/bert/DistributedGridProject/manning-energy-resources/scaffold/src/main/java/streams/DeviceEventProcessing.java][streams.DeviceEventProcessing.java]] contains the setup of the device event processing topology.
    This also implements the DropWizard Managed interface, so that the stream can be started/stopped
    when the webserver starts/stops.
    This also calls on StreamsConfiguration to find out where the Kafka Brokers are and
    where the Schema Resistry can be found.

** Storing Events in a Database
